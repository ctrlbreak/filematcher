---
phase: 04-actions-logging
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - file_matcher.py
autonomous: true

must_haves:
  truths:
    - "Hardlink action replaces duplicate file with hard link to master"
    - "Symlink action replaces duplicate file with symbolic link to master"
    - "Delete action removes duplicate file"
    - "Failed operations do not halt processing of remaining files"
    - "Original file is recoverable if link creation fails"
  artifacts:
    - path: "file_matcher.py"
      provides: "Action execution functions"
      exports: ["execute_action", "safe_replace_with_link", "already_hardlinked", "determine_exit_code"]
  key_links:
    - from: "execute_action()"
      to: "safe_replace_with_link()"
      via: "dispatch based on action type"
      pattern: "safe_replace_with_link.*duplicate.*master.*action"
    - from: "safe_replace_with_link()"
      to: "Path.hardlink_to() / Path.symlink_to() / Path.unlink()"
      via: "temp-rename safety pattern"
      pattern: "filematcher_tmp"
---

<objective>
Implement the core action execution engine that performs hardlink, symlink, and delete operations on duplicate files.

Purpose: This is the foundation for Phase 4 - the actual file modification logic that replaces duplicates with links or deletes them. Must handle errors gracefully and provide rollback capability.

Output: Functions for safe file replacement with temp-rename pattern, already-linked detection, and continue-on-error execution loop.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-actions-logging/04-CONTEXT.md
@.planning/phases/04-actions-logging/04-RESEARCH.md
@file_matcher.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement safe replacement functions</name>
  <files>file_matcher.py</files>
  <action>
Add three new functions to file_matcher.py after the existing check_cross_filesystem() function:

1. `already_hardlinked(file1: str, file2: str) -> bool`:
   - Check if two files share the same inode AND device
   - Use os.stat() to get st_ino and st_dev
   - Return True if both match, False otherwise
   - Catch OSError and return False

2. `safe_replace_with_link(duplicate: Path, master: Path, action: str) -> tuple[bool, str]`:
   - Implement temp-rename safety pattern per CONTEXT.md
   - Use `.filematcher_tmp` suffix (not just `.tmp` to avoid collisions)
   - Step 1: Rename duplicate to temp location (duplicate.with_suffix(duplicate.suffix + '.filematcher_tmp'))
   - Step 2: Create link at original duplicate location
     - hardlink: duplicate.hardlink_to(master)
     - symlink: duplicate.symlink_to(master.resolve()) - absolute path per CONTEXT.md
     - delete: No link creation, just leave file removed
   - Step 3: Delete temp file on success
   - On failure: Restore temp to original location (best-effort)
   - Return (True, "") on success, (False, error_message) on failure
   - Note: For delete action, skip link creation step (just rename to temp, then delete temp)

3. `execute_action(duplicate: str, master: str, action: str, fallback_symlink: bool = False) -> tuple[bool, str, str]`:
   - Main dispatch function for executing actions
   - First check: If action is hardlink and already_hardlinked() returns True, return (True, "already linked", "skipped")
   - Wrap safe_replace_with_link() call
   - For hardlink: If fails with cross-device error and fallback_symlink is True, retry as symlink
   - Return (success, error_message, actual_action_used)
   - actual_action_used can be: "hardlink", "symlink", "symlink (fallback)", "delete", "skipped"

Use pathlib Path for all file operations. Import Path at top if not already imported (it is).
  </action>
  <verify>
Add temporary test code at bottom:
```python
if __name__ == "__main__" and len(sys.argv) > 1 and sys.argv[1] == "--test-actions":
    # Quick manual test
    import tempfile
    with tempfile.TemporaryDirectory() as tmpdir:
        master = Path(tmpdir) / "master.txt"
        dup = Path(tmpdir) / "dup.txt"
        master.write_text("content")
        dup.write_text("content")
        print(f"Before: dup exists={dup.exists()}")
        success, error, action_used = execute_action(str(dup), str(master), "hardlink")
        print(f"After: success={success}, error={error}, action={action_used}")
        print(f"After: dup exists={dup.exists()}, same inode={already_hardlinked(str(dup), str(master))}")
```
Run: `python file_matcher.py --test-actions`
Expected: success=True, same inode=True
Remove test code after verification.
  </verify>
  <done>
- already_hardlinked() detects same-inode files
- safe_replace_with_link() implements temp-rename pattern
- execute_action() dispatches to correct operation with fallback support
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement execution loop with continue-on-error</name>
  <files>file_matcher.py</files>
  <action>
Add two more functions after execute_action():

1. `determine_exit_code(success_count: int, failure_count: int) -> int`:
   - If failure_count == 0: return 0 (full success)
   - If success_count == 0 and failure_count > 0: return 1 (total failure)
   - Otherwise: return 3 (partial completion)
   - Per CONTEXT.md exit code convention

2. `execute_all_actions(duplicate_groups: list[tuple[str, list[str], str]], action: str, fallback_symlink: bool = False, verbose: bool = False) -> tuple[int, int, int, list[tuple[str, str]]]`:
   - Process all duplicate groups
   - For each (master_file, duplicates, reason) in duplicate_groups:
     - If master file doesn't exist: log warning, skip entire group, increment group_skipped
     - For each duplicate in duplicates:
       - If duplicate doesn't exist: log info (not counted as failure per CONTEXT.md)
       - Call execute_action()
       - Track success_count, failure_count
       - On failure: append (duplicate_path, error_message) to failed_list
   - Print progress to stderr if verbose: "Processing {n}/{total}..."
   - Return (success_count, failure_count, skipped_count, failed_list)
   - skipped_count = duplicates that no longer exist + already-linked files

Use logger.warning() for missing master, logger.info() for missing duplicate.
Print progress with print(..., file=sys.stderr) to keep stdout clean.
  </action>
  <verify>
Run existing tests to ensure no regressions: `python3 run_tests.py`
All 64 tests should pass.
  </verify>
  <done>
- determine_exit_code() returns correct codes per CONTEXT.md
- execute_all_actions() processes all groups with continue-on-error
- Progress output goes to stderr
- Missing master skips group, missing duplicate is warning only
  </done>
</task>

</tasks>

<verification>
- [ ] Functions added without breaking existing functionality
- [ ] Temp-rename pattern implemented correctly
- [ ] Cross-filesystem fallback logic in place
- [ ] Continue-on-error behavior implemented
- [ ] Exit code logic matches CONTEXT.md specification
- [ ] All 64 existing tests still pass
</verification>

<success_criteria>
1. `already_hardlinked()` correctly detects if two paths share same inode
2. `safe_replace_with_link()` uses temp-rename pattern and rolls back on failure
3. `execute_action()` handles hardlink, symlink, delete, and fallback scenarios
4. `execute_all_actions()` processes all files without halting on individual errors
5. `determine_exit_code()` returns 0, 1, or 3 per specification
6. All existing tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/04-actions-logging/04-01-SUMMARY.md`
</output>
